{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blatt 3\n",
    "## Aufgabe 8: Importance Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ Die Planck-Verteilung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Planck(x, N = 15 / np.pi**4): \n",
    "    return N * x**3 / (np.exp(x) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimme zunächst numerisch das Maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import brentq \n",
    "\n",
    "N = 15 / np.pi**4\n",
    "\n",
    "def diff_Planck(x):\n",
    "    return N * (3 * x**2 * (np.exp(x) - 1) - x**3 * np.exp(x)) / (np.exp(x) - 1)**2 \n",
    "\n",
    "xmax = brentq(diff_Planck, 1, 4) #root of derivation \n",
    "ymax = Planck(xmax) # max. value of planck distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktion für _Rejection Sampling_, um eine vordefinierte Länge des Samples \n",
    "zu erreichen, wird die gewünschte Anzahl aus der erzeugten Verteilung gezogen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rejection_sampling(u1, u2, function, length = 100000):\n",
    "    sample = u1[u2 <= function(u1)]\n",
    "    assert len(sample) >= length\n",
    "    return sample[np.random.randint(0, len(sample), length)], len(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwende Funktion um normales Rejection Sampling durchzuführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "xcut = 20 # cutoff \n",
    "totnumber = 500000 \n",
    "uniformx = np.random.uniform(0, xcut, totnumber) \n",
    "uniformy = np.random.uniform(0, ymax, totnumber)\n",
    "\n",
    "planck_sample_a, sample_len_a = Rejection_sampling(uniformx, uniformy, Planck)\n",
    "print(len(planck_sample_a))\n",
    "\n",
    "elapsed_a = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Bestimme zunächst den Schnittpunkt der Majoranten _x_s_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff(x, N = 15 / np.pi**4, xmax = xmax):\n",
    "    return ymax - 200 * N * x**(-0.1) * np.exp(-x**(0.9)) \n",
    "    #difference of functions has to be zero  \n",
    "\n",
    "x_s = brentq(diff, 1, 6)\n",
    "print(f'Schnittpunkt x_s = {x_s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementiere die Majorante _g(x)_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_g(x, x_s = x_s, N = 15 / np.pi**4):\n",
    "    y = np.zeros(len(x))\n",
    "    y[x <= x_s] = ymax\n",
    "    y[x > x_s] = 200 * N * x[x >= x_s]**(-0.1) * np.exp(-x[x >= x_s]**(0.9))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun soll zunächst ein Sample erzeugt werden, dass gemäß $g(x)$ verteilt ist. Dies wird einzeln für $x \\leq x_s$ und $x > x_s$ gemacht. Die richtige Anzahl an Zufallszahlen rechts und links von $x_s$ ist aus dem Verhältnis der Flächen unter $g(x)$ berechenbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_G(y, x_s = x_s): #inverse CDF for x > x_s\n",
    "    return (- np.log(np.exp(-x_s**(0.9)) \n",
    "                     + y * (- np.exp(-x_s**(0.9))) ))**(10 / 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "norm = x_s * ymax + 2000 / 9 * N * (np.exp(-x_s**(9/10)))\n",
    "#total norm of g(x) \n",
    "\n",
    "\n",
    "part_uniform = int(x_s * ymax / norm * totnumber) \n",
    "\n",
    "uniformx_greater_x_s = np.random.uniform(0, 1, totnumber - part_uniform)\n",
    "sample_greater_x_s = inv_G(uniformx_greater_x_s)\n",
    "\n",
    "sample_less_x_s = np.random.uniform(0, x_s, part_uniform)\n",
    "uniformy = np.random.uniform(0, 1, totnumber)\n",
    "sample_g = np.concatenate([sample_less_x_s, sample_greater_x_s])\n",
    "\n",
    "\n",
    "planck_sample_b, sample_len_b = Rejection_sampling(sample_g, \n",
    "                                     func_g(sample_g) * uniformy, \n",
    "                                     Planck)\n",
    "\n",
    "\n",
    "elapsed_b = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "xplot = np.linspace(0.01, 30, 1000)\n",
    "\n",
    "\n",
    "mask = func_g(sample_g) * uniformy <= Planck(sample_g)\n",
    "plt.scatter(sample_g[mask], func_g(sample_g[mask]) * uniformy[mask], \n",
    "            marker = '.', color = 'g', label = 'Gespeichert')\n",
    "\n",
    "plt.scatter(sample_g[mask == False], \n",
    "            func_g(sample_g[mask == False]) * uniformy[mask == False], \n",
    "            marker = '.', color = 'r', label = 'Verworfen')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ Stelle die Datensätze aus a) und b), sowie die Theoriekurve dar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 10))\n",
    "\n",
    "fig.add_subplot(121)\n",
    "plt.hist(planck_sample_a, bins = 30, histtype = 'step',\n",
    "         density = True, \n",
    "         label = 'Aufgabenteil a)', \n",
    "         linewidth = 3)\n",
    "plt.plot(xplot, Planck(xplot), \n",
    "         color = 'r', linewidth = 3, label = 'Theorie')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "fig.add_subplot(122)\n",
    "plt.hist(planck_sample_b, bins = 30, histtype = 'step',\n",
    "         density = True, \n",
    "         label = 'Aufgabenteil b)', \n",
    "         linewidth = 3)\n",
    "plt.plot(xplot, Planck(xplot), \n",
    "         color = 'r', linewidth = 3, label = 'Theorie')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ Vergleiche Laufzeiten und Effizienzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Laufzeit a): {elapsed_a}s')\n",
    "print(f'Effizienz a): {sample_len_a / totnumber * 100}%')\n",
    "\n",
    "print(f'Laufzeit b): {elapsed_b}s')\n",
    "print(f'Effizienz b): {sample_len_b / totnumber * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kommentar: Die Laufzeit ist bei Methode a) etwas besser. Das liegt daran, dass für Methode b) zunächst noch Rechnungen durchgeführt werden müssen, um die Daten gemäß der Majorante zu verteilen. Die Effizienz ist dadurch in b) jedoch wesentlich besser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 9: Metropolis-Hastings-Algorithmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a)__ Ofenbar gilt für symmetrische Schrittvorschlagsverteilungen $g(x_i | x_j) = g(x_j | x_i)$. Daher geht z.B. für eine Gaußverteilung der Metropolis-Hastings-Algorithmus in den Metropolis-Algorithmus über."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Implementiere den Metropolis Hastings Algorithmus mit einer Gleichverteilung als Schrittvorschlagsfunktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis(distribution, x0, stepsize = 2, length = 100000):\n",
    "    x = [x0]\n",
    "    for i in range(length):\n",
    "        next_x = np.random.uniform(x[i] - stepsize, x[i] + stepsize)\n",
    "        prob = min(1, distribution(next_x) / distribution(x[i]))\n",
    "        xi = np.random.uniform(0, 1)\n",
    "        if prob >= xi and next_x >= 0:\n",
    "            x.append(next_x)\n",
    "        else:    \n",
    "            x.append(x[i])\n",
    "            \n",
    "    return np.array(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = metropolis(distribution = Planck, x0 = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, binedges = np.histogram(x, bins = 20)\n",
    "normed_counts = counts / sum(counts * np.diff(binedges)) \n",
    "\n",
    "xplot = np.linspace(0.01, 30, 1000)\n",
    "plt.errorbar(x = (binedges[:-1] + binedges[1:]) * 0.5, \n",
    "             y = normed_counts, xerr = np.diff(binedges) * 0.5, linestyle = '',\n",
    "            label = 'Daten')\n",
    "plt.plot(xplot, Planck(xplot), zorder = 1, color = 'r')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logarithmische Darstellung zeigt, dass die erzeugte Verteilung nicht so gut an die Theoriekurve passt für Werte, ab ca. $x = 20$. Dies könnte an dem schlecht gewählten Startpunkt liegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xplot = np.linspace(0.01, 30, 1000)\n",
    "plt.errorbar(x = (binedges[:-1] + binedges[1:]) * 0.5, \n",
    "             y = normed_counts, xerr = np.diff(binedges) * 0.5, linestyle = '',\n",
    "            label = 'Daten')\n",
    "plt.plot(xplot, Planck(xplot), zorder = 1, color = 'r')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d) Traceplot__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(range(len(x)), x)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kommentar: Man erkennt deutlich die Burn-In-Phase. Für weitere Iterationen schwanken die Werte um das Maximum der Verteilung bei etwa 3. Man erkennt einen Trend hin zu einer größeren Streuug der Daten um die Maximalstelle. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
